"""
LinkedIn Scraper com SessÃ£o Salva e RotaÃ§Ã£o de Proxy
=====================================================

Script de exemplo para fazer scraping no LinkedIn usando:
- SessÃ£o salva (nÃ£o precisa fazer login)
- RotaÃ§Ã£o automÃ¡tica de proxies
- Anti-detecÃ§Ã£o
- Enriquecimento de dados (API BigDataCorp)

Uso:
    python linkedin_scraper.py
"""

import time
import random
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.common.exceptions import TimeoutException, NoSuchElementException

from selenium_linkedin import ProxyManager, ProxyRotation, SessionManager, ChromeConfig
from utils import enrich_and_save  # Importar nossa nova funÃ§Ã£o


class LinkedInScraper:
    """
    Scraper do LinkedIn com recursos avanÃ§ados
    """
    
    def __init__(self, headless: bool = False, use_proxy: bool = True):
        """
        Inicializa o scraper
        
        Args:
            headless: Se True, executa sem interface grÃ¡fica
            use_proxy: Se True, usa proxy da lista
        """
        self.headless = headless
        self.use_proxy = use_proxy
        self.driver = None
        
        # Gerenciador de sessÃ£o
        self.session_manager = SessionManager(profile_name="linkedin")
        
        # Gerenciador de proxies (se habilitado)
        self.proxy_manager = None
        self.current_proxy = None
        
        if use_proxy:
            self.proxy_manager = ProxyManager(
                proxy_file="proxies.txt",
                rotation_mode=ProxyRotation.SEQUENTIAL
            )
            
        # Lista para armazenar nomes coletados
        self.collected_names = []
    
    def start(self):
        """Inicializa o navegador"""
        print("\n" + "="*60)
        print("INICIANDO LINKEDIN SCRAPER")
        print("="*60 + "\n")
        
        # Verificar se tem sessÃ£o salva
        if not self.session_manager.profile_exists():
            print("âŒ ERRO: SessÃ£o nÃ£o encontrada!")
            print("\nğŸ‘‰ Execute primeiro: python setup_linkedin_session.py")
            print("   ou: make session\n")
            return False
        
        # Obter prÃ³ximo proxy (se habilitado)
        if self.use_proxy and self.proxy_manager:
            self.current_proxy = self.proxy_manager.get_next_proxy()
            
            if not self.current_proxy:
                print("âš ï¸  Nenhum proxy disponÃ­vel. Continuando sem proxy...")
        
        # Configurar Chrome
        chrome_config = ChromeConfig(
            headless=self.headless,
            profile_path=self.session_manager.get_profile_path(),
            proxy=self.current_proxy
        )
        
        # Criar driver
        self.driver = chrome_config.create_driver()
        
        print("\nâœ… Navegador iniciado!")
        return True
    
    def stop(self):
        """Fecha o navegador"""
        if self.driver:
            print("\nğŸ”´ Fechando navegador...")
            self.driver.quit()
            print("âœ… Navegador fechado")
    
    def random_delay(self, min_sec: float = 1.0, max_sec: float = 3.0):
        """Delay aleatÃ³rio para parecer mais humano"""
        delay = random.uniform(min_sec, max_sec)
        time.sleep(delay)
    
    def navigate_to_linkedin(self):
        """Navega para o LinkedIn"""
        print("\nğŸŒ Navegando para LinkedIn...")
        self.driver.get("https://www.linkedin.com/feed/")
        self.random_delay(2, 4)
    
    def check_login_status(self) -> bool:
        """
        Verifica se estÃ¡ logado no LinkedIn
        
        Returns:
            True se estÃ¡ logado, False caso contrÃ¡rio
        """
        try:
            # Tentar encontrar elementos que sÃ³ aparecem quando logado
            WebDriverWait(self.driver, 10).until(
                EC.presence_of_element_located((By.ID, "global-nav"))
            )
            print("âœ… Login verificado - VocÃª estÃ¡ logado!")
            return True
        except TimeoutException:
            print("âŒ NÃ£o estÃ¡ logado. Execute o setup da sessÃ£o primeiro.")
            return False
    
    def search_people(self, query: str, max_results: int = 10):
        """
        Busca pessoas no LinkedIn e coleta nomes
        
        Args:
            query: Termo de busca
            max_results: MÃ¡ximo de resultados
        """
        try:
            print(f"\nğŸ” Buscando: {query}")
            
            # Ir para busca
            search_url = f"https://www.linkedin.com/search/results/people/?keywords={query}"
            self.driver.get(search_url)
            self.random_delay(3, 5)
            
            # Aguardar resultados carregarem
            WebDriverWait(self.driver, 15).until(
                EC.presence_of_element_located((By.CSS_SELECTOR, ".search-results-container"))
            )
            
            print("âœ… Resultados carregados")
            
            # Scroll para carregar mais resultados
            self.driver.execute_script("window.scrollTo(0, document.body.scrollHeight/2);")
            self.random_delay(1, 2)
            self.driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
            self.random_delay(2, 3)
            
            # Coletar nomes
            results = self.driver.find_elements(By.CSS_SELECTOR, ".entity-result__title-text a span[aria-hidden='true']")
            
            print(f"\nğŸ“‹ Encontrados {len(results)} resultados na pÃ¡gina:\n")
            
            count = 0
            for result in results:
                if count >= max_results:
                    break
                    
                try:
                    name = result.text.strip()
                    if name and name not in self.collected_names:
                        print(f"ğŸ‘¤ Coletado: {name}")
                        self.collected_names.append(name)
                        count += 1
                except:
                    continue
            
            print(f"\nâœ… Total coletado nesta busca: {count}")
            return count
            
        except Exception as e:
            print(f"âŒ Erro na busca: {e}")
            return 0
    
    def enrich_data(self):
        """
        Enriquece os dados coletados usando a API BigDataCorp
        """
        if not self.collected_names:
            print("\nâš ï¸ Nenhum nome coletado para enriquecer.")
            return
            
        print(f"\nğŸ”„ Iniciando enriquecimento de {len(self.collected_names)} nomes...")
        
        # Chama a funÃ§Ã£o do utils.py
        enrich_and_save(self.collected_names)


def main():
    """FunÃ§Ã£o principal"""
    print("""
    â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
    â•‘      LINKEDIN SCRAPER + ENRIQUECIMENTO DE DADOS            â•‘
    â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    """)
    
    # Criar scraper
    scraper = LinkedInScraper(
        headless=False,  # True para modo headless, False para ver o navegador
        use_proxy=True   # True para usar proxy, False para nÃ£o usar
    )
    
    try:
        # Iniciar navegador
        if not scraper.start():
            return
        
        # Navegar para LinkedIn
        scraper.navigate_to_linkedin()
        
        # Verificar login
        if not scraper.check_login_status():
            return
            
        # ========================================================
        # CONFIGURE SUA BUSCA AQUI
        # ========================================================
        termo_busca = "Recrutador TI"  # Exemplo
        quantidade = 5                 # Quantidade de perfis
        # ========================================================
        
        # 1. Buscar e coletar nomes
        scraper.search_people(termo_busca, max_results=quantidade)
        
        # 2. Enriquecer dados (API) e salvar CSV
        scraper.enrich_data()
        
    except KeyboardInterrupt:
        print("\n\nâš ï¸  Interrompido pelo usuÃ¡rio")
    
    except Exception as e:
        print(f"\nâŒ Erro: {e}")
    
    finally:
        # Sempre fechar o navegador
        scraper.stop()
    
    print("\nâœ… Processo finalizado com sucesso!")


if __name__ == "__main__":
    main()

"""
Exemplo de Web Scraper usando Selenium
"""
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.common.exceptions import TimeoutException, NoSuchElementException
import time
from config import get_driver


class WebScraper:
    """
    Classe para realizar web scraping com Selenium
    """
    
    def __init__(self, headless=False):
        """
        Inicializa o scraper
        
        Args:
            headless (bool): Se True, executa sem abrir janela do navegador
        """
        self.headless = headless
        self.driver = None
    
    def start(self):
        """Inicializa o driver do Selenium"""
        print(f"ğŸš€ Iniciando navegador {'(modo headless)' if self.headless else '(modo visual)'}...")
        self.driver = get_driver(headless=self.headless)
        print("âœ… Navegador iniciado com sucesso!")
    
    def stop(self):
        """Fecha o driver do Selenium"""
        if self.driver:
            self.driver.quit()
            print("ğŸ”´ Navegador fechado.")
    
    def navigate_to(self, url):
        """
        Navega para uma URL
        
        Args:
            url (str): URL de destino
        """
        print(f"ğŸŒ Navegando para: {url}")
        self.driver.get(url)
        time.sleep(2)  # Pequena pausa para carregar
    
    def wait_for_element(self, by, value, timeout=10):
        """
        Espera atÃ© que um elemento esteja presente na pÃ¡gina
        
        Args:
            by: Tipo de seletor (By.ID, By.CSS_SELECTOR, By.XPATH, etc)
            value: Valor do seletor
            timeout: Tempo mÃ¡ximo de espera em segundos
        
        Returns:
            WebElement ou None se nÃ£o encontrado
        """
        try:
            element = WebDriverWait(self.driver, timeout).until(
                EC.presence_of_element_located((by, value))
            )
            return element
        except TimeoutException:
            print(f"âš ï¸ Elemento nÃ£o encontrado: {value}")
            return None
    
    def get_element_text(self, by, value):
        """
        ObtÃ©m o texto de um elemento
        
        Args:
            by: Tipo de seletor
            value: Valor do seletor
        
        Returns:
            str: Texto do elemento ou None
        """
        try:
            element = self.driver.find_element(by, value)
            return element.text
        except NoSuchElementException:
            print(f"âš ï¸ Elemento nÃ£o encontrado: {value}")
            return None
    
    def get_elements_text(self, by, value):
        """
        ObtÃ©m o texto de mÃºltiplos elementos
        
        Args:
            by: Tipo de seletor
            value: Valor do seletor
        
        Returns:
            list: Lista com textos dos elementos
        """
        try:
            elements = self.driver.find_elements(by, value)
            return [elem.text for elem in elements if elem.text]
        except NoSuchElementException:
            print(f"âš ï¸ Elementos nÃ£o encontrados: {value}")
            return []
    
    def click_element(self, by, value):
        """
        Clica em um elemento
        
        Args:
            by: Tipo de seletor
            value: Valor do seletor
        """
        try:
            element = self.wait_for_element(by, value)
            if element:
                element.click()
                print(f"âœ… Clicado em: {value}")
                time.sleep(1)
        except Exception as e:
            print(f"âŒ Erro ao clicar: {e}")
    
    def type_text(self, by, value, text):
        """
        Digita texto em um campo
        
        Args:
            by: Tipo de seletor
            value: Valor do seletor
            text: Texto a ser digitado
        """
        try:
            element = self.wait_for_element(by, value)
            if element:
                element.clear()
                element.send_keys(text)
                print(f"âœ… Texto digitado em: {value}")
        except Exception as e:
            print(f"âŒ Erro ao digitar: {e}")
    
    def take_screenshot(self, filename="screenshot.png"):
        """
        Tira um screenshot da pÃ¡gina
        
        Args:
            filename: Nome do arquivo para salvar
        """
        self.driver.save_screenshot(filename)
        print(f"ğŸ“¸ Screenshot salvo: {filename}")
    
    def get_page_title(self):
        """Retorna o tÃ­tulo da pÃ¡gina"""
        return self.driver.title
    
    def get_current_url(self):
        """Retorna a URL atual"""
        return self.driver.current_url


def exemplo_google_search():
    """
    Exemplo 1: Busca no Google
    """
    print("\n" + "="*60)
    print("EXEMPLO 1: Busca no Google")
    print("="*60 + "\n")
    
    # Criar scraper (headless=False para ver o navegador)
    scraper = WebScraper(headless=False)
    
    try:
        # Iniciar navegador
        scraper.start()
        
        # Navegar para o Google
        scraper.navigate_to("https://www.google.com")
        
        # Aguardar e obter o tÃ­tulo
        print(f"ğŸ“„ TÃ­tulo da pÃ¡gina: {scraper.get_page_title()}")
        
        # Procurar pela caixa de busca e digitar
        scraper.type_text(By.NAME, "q", "Selenium Python Web Scraping")
        
        # Clicar no botÃ£o de busca (ou pressionar Enter)
        scraper.click_element(By.NAME, "btnK")
        
        # Aguardar resultados carregarem
        time.sleep(3)
        
        # Pegar os tÃ­tulos dos resultados
        print("\nğŸ” Resultados da busca:")
        results = scraper.get_elements_text(By.CSS_SELECTOR, "h3")
        for i, result in enumerate(results[:5], 1):  # Primeiros 5 resultados
            print(f"{i}. {result}")
        
        # Tirar screenshot
        scraper.take_screenshot("google_search.png")
        
        # Aguardar um pouco para visualizar
        time.sleep(3)
        
    except Exception as e:
        print(f"âŒ Erro durante scraping: {e}")
    
    finally:
        # Sempre fechar o navegador
        scraper.stop()


def exemplo_quotes_scraping():
    """
    Exemplo 2: Scraping de citaÃ§Ãµes do site quotes.toscrape.com
    """
    print("\n" + "="*60)
    print("EXEMPLO 2: Scraping de CitaÃ§Ãµes")
    print("="*60 + "\n")
    
    # Criar scraper em modo headless (mais rÃ¡pido)
    scraper = WebScraper(headless=True)
    
    try:
        # Iniciar navegador
        scraper.start()
        
        # Navegar para o site de exemplo
        scraper.navigate_to("http://quotes.toscrape.com")
        
        print(f"ğŸ“„ TÃ­tulo: {scraper.get_page_title()}")
        
        # Aguardar as citaÃ§Ãµes carregarem
        scraper.wait_for_element(By.CLASS_NAME, "quote")
        
        # Pegar todas as citaÃ§Ãµes da pÃ¡gina
        quotes = scraper.driver.find_elements(By.CLASS_NAME, "quote")
        
        print(f"\nğŸ“š Encontradas {len(quotes)} citaÃ§Ãµes:\n")
        
        for i, quote in enumerate(quotes, 1):
            # Pegar o texto da citaÃ§Ã£o
            text = quote.find_element(By.CLASS_NAME, "text").text
            # Pegar o autor
            author = quote.find_element(By.CLASS_NAME, "author").text
            # Pegar as tags
            tags = quote.find_elements(By.CLASS_NAME, "tag")
            tag_list = [tag.text for tag in tags]
            
            print(f"{i}. {text}")
            print(f"   Autor: {author}")
            print(f"   Tags: {', '.join(tag_list)}\n")
        
        # Tirar screenshot
        scraper.take_screenshot("quotes_page.png")
        
    except Exception as e:
        print(f"âŒ Erro durante scraping: {e}")
    
    finally:
        scraper.stop()


def exemplo_navegacao_multiplas_paginas():
    """
    Exemplo 3: NavegaÃ§Ã£o entre mÃºltiplas pÃ¡ginas
    """
    print("\n" + "="*60)
    print("EXEMPLO 3: NavegaÃ§Ã£o Entre PÃ¡ginas")
    print("="*60 + "\n")
    
    scraper = WebScraper(headless=True)
    
    try:
        scraper.start()
        
        # Navegar para a primeira pÃ¡gina
        scraper.navigate_to("http://quotes.toscrape.com")
        
        # Coletar citaÃ§Ãµes de 3 pÃ¡ginas
        all_quotes = []
        
        for page in range(1, 4):  # PÃ¡ginas 1, 2 e 3
            print(f"\nğŸ“„ Coletando dados da pÃ¡gina {page}...")
            
            # Aguardar citaÃ§Ãµes carregarem
            scraper.wait_for_element(By.CLASS_NAME, "quote")
            
            # Pegar citaÃ§Ãµes da pÃ¡gina atual
            quotes = scraper.driver.find_elements(By.CLASS_NAME, "quote")
            
            for quote in quotes:
                text = quote.find_element(By.CLASS_NAME, "text").text
                author = quote.find_element(By.CLASS_NAME, "author").text
                all_quotes.append({"text": text, "author": author})
            
            # Tentar ir para prÃ³xima pÃ¡gina
            try:
                next_button = scraper.driver.find_element(By.CSS_SELECTOR, ".next > a")
                next_button.click()
                time.sleep(2)
            except NoSuchElementException:
                print("âœ… NÃ£o hÃ¡ mais pÃ¡ginas.")
                break
        
        print(f"\nğŸ“Š Total de citaÃ§Ãµes coletadas: {len(all_quotes)}")
        
        # Mostrar algumas citaÃ§Ãµes
        print("\nğŸ¯ Primeiras 5 citaÃ§Ãµes coletadas:")
        for i, quote in enumerate(all_quotes[:5], 1):
            print(f"{i}. \"{quote['text']}\" - {quote['author']}")
        
    except Exception as e:
        print(f"âŒ Erro durante scraping: {e}")
    
    finally:
        scraper.stop()


if __name__ == "__main__":
    """
    Executa os exemplos de scraping
    """
    print("""
    â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
    â•‘         EXEMPLOS DE WEB SCRAPING COM SELENIUM              â•‘
    â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    """)
    
    # Descomente o exemplo que deseja executar:
    
    # Exemplo 1: Busca no Google (modo visual)
    # exemplo_google_search()
    
    # Exemplo 2: Scraping de citaÃ§Ãµes (modo headless)
    exemplo_quotes_scraping()
    
    # Exemplo 3: NavegaÃ§Ã£o entre mÃºltiplas pÃ¡ginas
    # exemplo_navegacao_multiplas_paginas()
    
    print("\nâœ… Scraping finalizado!")
    print("\nğŸ’¡ Dica: Edite este arquivo e descomente os exemplos que deseja testar!")


